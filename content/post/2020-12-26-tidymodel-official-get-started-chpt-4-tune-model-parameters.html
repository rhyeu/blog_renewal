---
title: tidymodel official get started chpt 4 Tune model parameters
author: 류성균
date: '2020-12-26'
slug: tidymodel-official-get-started-chpt-4-tune-model-parameters
categories:
  - R
tags:
  - tidymodels
  - tidyverse
  - machine-learning
keywords:
  - tech
---

<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<!--more-->
<ul>
<li>reference : <a href="https://www.tidymodels.org/start/tuning/" class="uri">https://www.tidymodels.org/start/tuning/</a></li>
</ul>
<pre class="r"><code>library(tidymodels)  # for the tune package, along with the rest of tidymodels</code></pre>
<pre><code>## -- Attaching packages --------------------- tidymodels 0.1.1 --</code></pre>
<pre><code>## √ broom     0.7.0      √ recipes   0.1.13
## √ dials     0.0.8      √ rsample   0.0.7 
## √ dplyr     1.0.2      √ tibble    3.0.3 
## √ ggplot2   3.3.2      √ tidyr     1.1.2 
## √ infer     0.5.3      √ tune      0.1.1 
## √ modeldata 0.0.2      √ workflows 0.1.3 
## √ parsnip   0.1.3      √ yardstick 0.0.7 
## √ purrr     0.3.4</code></pre>
<pre><code>## -- Conflicts ------------------------ tidymodels_conflicts() --
## x purrr::discard() masks scales::discard()
## x dplyr::filter()  masks stats::filter()
## x dplyr::lag()     masks stats::lag()
## x recipes::step()  masks stats::step()</code></pre>
<pre class="r"><code># Helper packages
library(modeldata)   # for the cells data
library(vip)         # for variable importance plots</code></pre>
<pre><code>## 
## 다음의 패키지를 부착합니다: &#39;vip&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:utils&#39;:
## 
##     vi</code></pre>
<div id="the-cell-image-data-revisited" class="section level3">
<h3>The cell image data, revisited</h3>
<pre class="r"><code>data(cells, packages = &quot;modeldata&quot;)</code></pre>
<pre><code>## Warning in data(cells, packages = &quot;modeldata&quot;): data set &#39;modeldata&#39; not found</code></pre>
<pre class="r"><code>glimpse(cells)</code></pre>
<pre><code>## Rows: 2,019
## Columns: 58
## $ case                         &lt;fct&gt; Test, Train, Train, Train, Test, Test,...
## $ class                        &lt;fct&gt; PS, PS, WS, PS, PS, WS, WS, PS, WS, WS...
## $ angle_ch_1                   &lt;dbl&gt; 143.247705, 133.752037, 106.646387, 69...
## $ area_ch_1                    &lt;int&gt; 185, 819, 431, 298, 285, 172, 177, 251...
## $ avg_inten_ch_1               &lt;dbl&gt; 15.71186, 31.92327, 28.03883, 19.45614...
## $ avg_inten_ch_2               &lt;dbl&gt; 4.954802, 206.878517, 116.315534, 102....
## $ avg_inten_ch_3               &lt;dbl&gt; 9.548023, 69.916880, 63.941748, 28.217...
## $ avg_inten_ch_4               &lt;dbl&gt; 2.214689, 164.153453, 106.696602, 31.0...
## $ convex_hull_area_ratio_ch_1  &lt;dbl&gt; 1.124509, 1.263158, 1.053310, 1.202625...
## $ convex_hull_perim_ratio_ch_1 &lt;dbl&gt; 0.9196827, 0.7970801, 0.9354750, 0.865...
## $ diff_inten_density_ch_1      &lt;dbl&gt; 29.51923, 31.87500, 32.48771, 26.73228...
## $ diff_inten_density_ch_3      &lt;dbl&gt; 13.77564, 43.12228, 35.98577, 22.91732...
## $ diff_inten_density_ch_4      &lt;dbl&gt; 6.826923, 79.308424, 51.357050, 26.393...
## $ entropy_inten_ch_1           &lt;dbl&gt; 4.969781, 6.087592, 5.883557, 5.420065...
## $ entropy_inten_ch_3           &lt;dbl&gt; 4.371017, 6.642761, 6.683000, 5.436732...
## $ entropy_inten_ch_4           &lt;dbl&gt; 2.718884, 7.880155, 7.144601, 5.778329...
## $ eq_circ_diam_ch_1            &lt;dbl&gt; 15.36954, 32.30558, 23.44892, 19.50279...
## $ eq_ellipse_lwr_ch_1          &lt;dbl&gt; 3.060676, 1.558394, 1.375386, 3.391220...
## $ eq_ellipse_oblate_vol_ch_1   &lt;dbl&gt; 336.9691, 2232.9055, 802.1945, 724.714...
## $ eq_ellipse_prolate_vol_ch_1  &lt;dbl&gt; 110.0963, 1432.8246, 583.2504, 213.703...
## $ eq_sphere_area_ch_1          &lt;dbl&gt; 742.1156, 3278.7256, 1727.4104, 1194.9...
## $ eq_sphere_vol_ch_1           &lt;dbl&gt; 1900.996, 17653.525, 6750.985, 3884.08...
## $ fiber_align_2_ch_3           &lt;dbl&gt; 1.000000, 1.487935, 1.300522, 1.220424...
## $ fiber_align_2_ch_4           &lt;dbl&gt; 1.000000, 1.352374, 1.522316, 1.733250...
## $ fiber_length_ch_1            &lt;dbl&gt; 26.98132, 64.28230, 21.14115, 43.14112...
## $ fiber_width_ch_1             &lt;dbl&gt; 7.410365, 13.167079, 21.141150, 7.4044...
## $ inten_cooc_asm_ch_3          &lt;dbl&gt; 0.011183899, 0.028051061, 0.006862315,...
## $ inten_cooc_asm_ch_4          &lt;dbl&gt; 0.050448005, 0.012594975, 0.006141691,...
## $ inten_cooc_contrast_ch_3     &lt;dbl&gt; 40.751777, 8.227953, 14.446074, 7.2994...
## $ inten_cooc_contrast_ch_4     &lt;dbl&gt; 13.895439, 6.984046, 16.700843, 13.390...
## $ inten_cooc_entropy_ch_3      &lt;dbl&gt; 7.199458, 6.822138, 7.580100, 6.312641...
## $ inten_cooc_entropy_ch_4      &lt;dbl&gt; 5.249744, 7.098988, 7.671478, 7.197026...
## $ inten_cooc_max_ch_3          &lt;dbl&gt; 0.07741935, 0.15321477, 0.02835052, 0....
## $ inten_cooc_max_ch_4          &lt;dbl&gt; 0.17197452, 0.07387141, 0.02319588, 0....
## $ kurt_inten_ch_1              &lt;dbl&gt; -0.656744087, -0.248769067, -0.2934846...
## $ kurt_inten_ch_3              &lt;dbl&gt; -0.608058268, -0.330783900, 1.05128133...
## $ kurt_inten_ch_4              &lt;dbl&gt; 0.7258145, -0.2652638, 0.1506140, -0.3...
## $ length_ch_1                  &lt;dbl&gt; 26.20779, 47.21855, 28.14303, 37.85957...
## $ neighbor_avg_dist_ch_1       &lt;dbl&gt; 370.4543, 174.4442, 158.4774, 206.3344...
## $ neighbor_min_dist_ch_1       &lt;dbl&gt; 99.10349, 30.11114, 34.94477, 33.08030...
## $ neighbor_var_dist_ch_1       &lt;dbl&gt; 127.96080, 81.38063, 90.43768, 116.892...
## $ perim_ch_1                   &lt;dbl&gt; 68.78338, 154.89876, 84.56460, 101.091...
## $ shape_bfr_ch_1               &lt;dbl&gt; 0.6651480, 0.5397584, 0.7243116, 0.589...
## $ shape_lwr_ch_1               &lt;dbl&gt; 2.462450, 1.468181, 1.328408, 2.826854...
## $ shape_p_2_a_ch_1             &lt;dbl&gt; 1.883006, 2.255810, 1.272193, 2.545840...
## $ skew_inten_ch_1              &lt;dbl&gt; 0.45450484, 0.39870467, 0.47248709, 0....
## $ skew_inten_ch_3              &lt;dbl&gt; 0.46039340, 0.61973079, 0.97137879, 0....
## $ skew_inten_ch_4              &lt;dbl&gt; 1.2327736, 0.5272631, 0.3247065, 0.604...
## $ spot_fiber_count_ch_3        &lt;int&gt; 1, 4, 2, 4, 1, 1, 0, 2, 1, 1, 1, 0, 0,...
## $ spot_fiber_count_ch_4        &lt;dbl&gt; 5, 12, 7, 8, 8, 5, 5, 8, 12, 8, 5, 6, ...
## $ total_inten_ch_1             &lt;int&gt; 2781, 24964, 11552, 5545, 6603, 53779,...
## $ total_inten_ch_2             &lt;dbl&gt; 701, 160998, 47511, 28870, 30306, 1076...
## $ total_inten_ch_3             &lt;int&gt; 1690, 54675, 26344, 8042, 5569, 21234,...
## $ total_inten_ch_4             &lt;int&gt; 392, 128368, 43959, 8843, 11037, 57231...
## $ var_inten_ch_1               &lt;dbl&gt; 12.47468, 18.80923, 17.29564, 13.81897...
## $ var_inten_ch_3               &lt;dbl&gt; 7.609035, 56.715352, 37.671053, 30.005...
## $ var_inten_ch_4               &lt;dbl&gt; 2.714100, 118.388139, 49.470524, 24.74...
## $ width_ch_1                   &lt;dbl&gt; 10.64297, 32.16126, 21.18553, 13.39283...</code></pre>
</div>
<div id="predicting-image-segmentation-but-better" class="section level3">
<h3>Predicting image segmentation, but better</h3>
<pre class="r"><code>set.seed(123)
cell_split &lt;- initial_split(cells %&gt;% select(-case), 
                            starta = class)

cell_train &lt;- training(cell_split)
cell_test &lt;- testing(cell_split)</code></pre>
</div>
<div id="tuning-hyperparameters" class="section level3">
<h3>Tuning hyperparameters</h3>
<pre class="r"><code>tune_spec &lt;- decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()) %&gt;% 
  set_engine(&quot;rpart&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)

tune_spec</code></pre>
<pre><code>## Decision Tree Model Specification (classification)
## 
## Main Arguments:
##   cost_complexity = tune()
##   tree_depth = tune()
## 
## Computational engine: rpart</code></pre>
<pre class="r"><code>### grid_regular from dials package
tree_grid &lt;- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5) # parameter별로 5개씩 테스트, 총 25개</code></pre>
<pre class="r"><code>tree_grid</code></pre>
<pre><code>## # A tibble: 25 x 2
##    cost_complexity tree_depth
##              &lt;dbl&gt;      &lt;int&gt;
##  1    0.0000000001          1
##  2    0.0000000178          1
##  3    0.00000316            1
##  4    0.000562              1
##  5    0.1                   1
##  6    0.0000000001          4
##  7    0.0000000178          4
##  8    0.00000316            4
##  9    0.000562              4
## 10    0.1                   4
## # ... with 15 more rows</code></pre>
<pre class="r"><code>tree_grid %&gt;% 
  count(tree_depth)</code></pre>
<pre><code>## # A tibble: 5 x 2
##   tree_depth     n
##        &lt;int&gt; &lt;int&gt;
## 1          1     5
## 2          4     5
## 3          8     5
## 4         11     5
## 5         15     5</code></pre>
<pre class="r"><code>tree_grid %&gt;% 
  count(cost_complexity)</code></pre>
<pre><code>## # A tibble: 5 x 2
##   cost_complexity     n
##             &lt;dbl&gt; &lt;int&gt;
## 1    0.0000000001     5
## 2    0.0000000178     5
## 3    0.00000316       5
## 4    0.000562         5
## 5    0.1              5</code></pre>
<pre class="r"><code>set.seed(234)
cell_folds &lt;- vfold_cv(cell_train)</code></pre>
</div>
<div id="model-tunning-with-a-grid" class="section level3">
<h3>Model tunning with a grid</h3>
<pre class="r"><code>set.seed(345)

tree_wf &lt;- workflow() %&gt;% 
  add_model(tune_spec) %&gt;% 
  add_formula(class ~ .) # add_recipe로 대체 가능능

tree_res &lt;-
  tree_wf %&gt;% 
  tune_grid(
    resamples = cell_folds,
    grid = tree_grid
  )

tree_res</code></pre>
<pre><code>## # Tuning results
## # 10-fold cross-validation 
## # A tibble: 10 x 4
##    splits             id     .metrics          .notes          
##    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          
##  1 &lt;split [1.4K/152]&gt; Fold01 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
##  2 &lt;split [1.4K/152]&gt; Fold02 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
##  3 &lt;split [1.4K/152]&gt; Fold03 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
##  4 &lt;split [1.4K/152]&gt; Fold04 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
##  5 &lt;split [1.4K/152]&gt; Fold05 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
##  6 &lt;split [1.4K/151]&gt; Fold06 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
##  7 &lt;split [1.4K/151]&gt; Fold07 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
##  8 &lt;split [1.4K/151]&gt; Fold08 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
##  9 &lt;split [1.4K/151]&gt; Fold09 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;
## 10 &lt;split [1.4K/151]&gt; Fold10 &lt;tibble [50 x 6]&gt; &lt;tibble [0 x 1]&gt;</code></pre>
<pre class="r"><code>tree_res %&gt;% 
  collect_metrics()</code></pre>
<pre><code>## # A tibble: 50 x 8
##    cost_complexity tree_depth .metric  .estimator  mean     n std_err .config
##              &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
##  1    0.0000000001          1 accuracy binary     0.764    10 0.0101  Model01
##  2    0.0000000001          1 roc_auc  binary     0.792    10 0.00804 Model01
##  3    0.0000000178          1 accuracy binary     0.764    10 0.0101  Model02
##  4    0.0000000178          1 roc_auc  binary     0.792    10 0.00804 Model02
##  5    0.00000316            1 accuracy binary     0.764    10 0.0101  Model03
##  6    0.00000316            1 roc_auc  binary     0.792    10 0.00804 Model03
##  7    0.000562              1 accuracy binary     0.764    10 0.0101  Model04
##  8    0.000562              1 roc_auc  binary     0.792    10 0.00804 Model04
##  9    0.1                   1 accuracy binary     0.764    10 0.0101  Model05
## 10    0.1                   1 roc_auc  binary     0.792    10 0.00804 Model05
## # ... with 40 more rows</code></pre>
<pre class="r"><code>tree_res %&gt;% 
  collect_metrics() %&gt;% 
  mutate(tree_depth = factor(tree_depth)) %&gt;% 
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = &quot;free&quot;, nrow = 2) + 
  scale_x_log10(labels = scales::label_number()) + 
  scale_color_viridis_d(option = &quot;plasma&quot;, begin = 0.9, end = 0)</code></pre>
<p><img src="/post/2020-12-26-tidymodel-official-get-started-chpt-4-tune-model-parameters_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code>tree_res %&gt;% 
  show_best(&quot;roc_auc&quot;)</code></pre>
<pre><code>## # A tibble: 5 x 8
##   cost_complexity tree_depth .metric .estimator  mean     n std_err .config
##             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
## 1    0.0000000001          4 roc_auc binary     0.847    10 0.00845 Model06
## 2    0.0000000178          4 roc_auc binary     0.847    10 0.00845 Model07
## 3    0.00000316            4 roc_auc binary     0.847    10 0.00845 Model08
## 4    0.000562              4 roc_auc binary     0.847    10 0.00845 Model09
## 5    0.0000000001         15 roc_auc binary     0.834    10 0.00917 Model21</code></pre>
<pre class="r"><code>best_tree &lt;- tree_res %&gt;% 
  select_best(&quot;roc_auc&quot;)

best_tree</code></pre>
<pre><code>## # A tibble: 1 x 3
##   cost_complexity tree_depth .config
##             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;  
## 1    0.0000000001          4 Model06</code></pre>
</div>
<div id="finalizing-our-model" class="section level3">
<h3>Finalizing our model</h3>
<pre class="r"><code>final_wf &lt;- tree_wf %&gt;% 
  finalize_workflow(best_tree)

final_wf</code></pre>
<pre><code>## == Workflow ===================================================
## Preprocessor: Formula
## Model: decision_tree()
## 
## -- Preprocessor -----------------------------------------------
## class ~ .
## 
## -- Model ------------------------------------------------------
## Decision Tree Model Specification (classification)
## 
## Main Arguments:
##   cost_complexity = 1e-10
##   tree_depth = 4
## 
## Computational engine: rpart</code></pre>
</div>
<div id="exploring-result" class="section level3">
<h3>Exploring result</h3>
<pre class="r"><code>final_tree &lt;- final_wf %&gt;% 
  fit(data = cell_train)

final_tree</code></pre>
<pre><code>## == Workflow [trained] =========================================
## Preprocessor: Formula
## Model: decision_tree()
## 
## -- Preprocessor -----------------------------------------------
## class ~ .
## 
## -- Model ------------------------------------------------------
## n= 1515 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 1515 542 PS (0.64224422 0.35775578)  
##    2) total_inten_ch_2&lt; 47256.5 738  61 PS (0.91734417 0.08265583)  
##      4) shape_p_2_a_ch_1&gt;=1.236425 717  48 PS (0.93305439 0.06694561) *
##      5) shape_p_2_a_ch_1&lt; 1.236425 21   8 WS (0.38095238 0.61904762)  
##       10) convex_hull_perim_ratio_ch_1&gt;=0.9698562 13   5 PS (0.61538462 0.38461538) *
##       11) convex_hull_perim_ratio_ch_1&lt; 0.9698562 8   0 WS (0.00000000 1.00000000) *
##    3) total_inten_ch_2&gt;=47256.5 777 296 WS (0.38095238 0.61904762)  
##      6) fiber_width_ch_1&lt; 11.37318 340 141 PS (0.58529412 0.41470588)  
##       12) kurt_inten_ch_1&gt;=-0.3204087 227  70 PS (0.69162996 0.30837004)  
##         24) var_inten_ch_1&lt; 214.8773 212  57 PS (0.73113208 0.26886792) *
##         25) var_inten_ch_1&gt;=214.8773 15   2 WS (0.13333333 0.86666667) *
##       13) kurt_inten_ch_1&lt; -0.3204087 113  42 WS (0.37168142 0.62831858)  
##         26) eq_ellipse_oblate_vol_ch_1&lt; 289.8015 17   4 PS (0.76470588 0.23529412) *
##         27) eq_ellipse_oblate_vol_ch_1&gt;=289.8015 96  29 WS (0.30208333 0.69791667) *
##      7) fiber_width_ch_1&gt;=11.37318 437  97 WS (0.22196796 0.77803204)  
##       14) entropy_inten_ch_4&gt;=7.700051 16   4 PS (0.75000000 0.25000000) *
##       15) entropy_inten_ch_4&lt; 7.700051 421  85 WS (0.20190024 0.79809976) *</code></pre>
<pre class="r"><code>final_tree %&gt;% 
  pull_workflow_fit() %&gt;% 
  vip()</code></pre>
<p><img src="/post/2020-12-26-tidymodel-official-get-started-chpt-4-tune-model-parameters_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
<div id="the-last-fit" class="section level3">
<h3>The last fit ?</h3>
<ul>
<li>last_fit과 fit의 차이는 뭐지?</li>
</ul>
<pre class="r"><code>final_fit &lt;- final_wf %&gt;% 
  last_fit(cell_split)

final_fit %&gt;% 
  collect_metrics()</code></pre>
<pre><code>## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.786
## 2 roc_auc  binary         0.819</code></pre>
<pre class="r"><code>final_fit %&gt;% 
  collect_predictions() %&gt;% 
  roc_curve(class, .pred_PS) %&gt;% 
  autoplot()</code></pre>
<p><img src="/post/2020-12-26-tidymodel-official-get-started-chpt-4-tune-model-parameters_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<ul>
<li>tuning할 수 있는 parameter 확인</li>
</ul>
<pre class="r"><code>args(decision_tree)</code></pre>
<pre><code>## function (mode = &quot;unknown&quot;, cost_complexity = NULL, tree_depth = NULL, 
##     min_n = NULL) 
## NULL</code></pre>
</div>
